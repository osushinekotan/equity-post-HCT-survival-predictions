{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "import config\n",
    "import polars as pl\n",
    "from catboost import CatBoostRegressor\n",
    "from preprocess import fe, load_data\n",
    "\n",
    "from src.customs.fold import add_kfold\n",
    "from src.customs.metrics import CatBoostMetric, Metric\n",
    "from src.model.sklearn_like import (\n",
    "    CatBoostRegressorWrapper,\n",
    ")\n",
    "from src.trainer.tabular.simple import single_inference_fn, single_train_fn\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = load_data(config=config, valid_ratio=config.VALID_RATIO)\n",
    "target_df = pl.read_csv(\"./data/extr_output/101/1/101.csv\").with_columns(pl.col(\"t_event_pred\") * 2)\n",
    "target_cols = [x for x in target_df.columns if x.startswith(\"t_\")]\n",
    "train_test_df = train_test_df.join(\n",
    "    target_df.select(\n",
    "        [\n",
    "            config.ID_COL,\n",
    "            *target_cols,\n",
    "        ],\n",
    "    ),\n",
    "    on=config.ID_COL,\n",
    "    how=\"left\",\n",
    ")\n",
    "config.META_COLS = set(config.META_COLS) | set(target_cols)\n",
    "\n",
    "features_df = fe(config=config, train_test_df=train_test_df)\n",
    "feature_names = sorted([x for x in features_df.columns if x.startswith(config.FEATURE_PREFIX)])\n",
    "cat_features = [x for x in feature_names if x.startswith(f\"{config.FEATURE_PREFIX}c_\")]\n",
    "\n",
    "\n",
    "def make_new_targets_by_race(\n",
    "    df: pl.DataFrame,\n",
    "    base_target_names: tuple[str] = (\"t_kmf\", \"t_bfhf\"),\n",
    "    lower_bound_pos: float = 0.0,\n",
    "    lower_bound_neg: float = 0.0,\n",
    "    pred_col: str = \"t_event_pred\",\n",
    "    race_group_col: str = \"race_group\",\n",
    ") -> pl.DataFrame:\n",
    "    for base_target_name in base_target_names:\n",
    "        new_target_name = f\"{base_target_name}_event_scaled2\"\n",
    "\n",
    "        # race group ごとに event==1 の scaling factor を計算\n",
    "        agg_pos = (\n",
    "            df.filter(pl.col(config.EVENT_COL) == 1)\n",
    "            .group_by(race_group_col)\n",
    "            .agg(\n",
    "                (pl.col(pred_col).log().min() / (lower_bound_pos - pl.col(base_target_name).min())).alias(\n",
    "                    \"scaling_factor_pos\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # race group ごとに event==0 の scaling factor を計算\n",
    "        agg_neg = (\n",
    "            df.filter(pl.col(config.EVENT_COL) == 0)\n",
    "            .group_by(race_group_col)\n",
    "            .agg(\n",
    "                (pl.col(pred_col).log().min() / (lower_bound_neg - pl.col(base_target_name).min())).alias(\n",
    "                    \"scaling_factor_neg\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 各 race group ごとの scaling factor を df に結合\n",
    "        df = df.join(agg_pos, on=race_group_col, how=\"left\").join(agg_neg, on=race_group_col, how=\"left\")\n",
    "\n",
    "        # race group ごとに条件に沿って新たなターゲットを算出\n",
    "        new_df = df.select(\n",
    "            pl.col(config.ID_COL),\n",
    "            pl.when(pl.col(config.EVENT_COL) == 1)\n",
    "            .then(pl.col(pred_col).log() / pl.col(\"scaling_factor_pos\") + pl.col(base_target_name))\n",
    "            .otherwise(pl.col(pred_col).log() / pl.col(\"scaling_factor_neg\") + pl.col(base_target_name))\n",
    "            .alias(new_target_name),\n",
    "        )\n",
    "        df = df.join(new_df, on=config.ID_COL, how=\"left\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "features_df = features_df.join(\n",
    "    make_new_targets_by_race(\n",
    "        target_df,\n",
    "        lower_bound_neg=0.0,\n",
    "        lower_bound_pos=0.0,\n",
    "    ).select(\n",
    "        pl.col(config.ID_COL),\n",
    "        pl.col(\"scaling_factor_pos\"),\n",
    "        pl.col(\"scaling_factor_neg\"),\n",
    "        pl.col(\"t_kmf_event_scaled2\").exp(),\n",
    "    ),\n",
    "    on=config.ID_COL,\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "\n",
    "def add_weight_by_race_group(features_df: pl.DataFrame, race_group: str) -> pl.DataFrame:\n",
    "    features_df = features_df.with_columns(pl.col(config.SURVIVAL_TIME_COL).alias(\"tmp_time\"))\n",
    "\n",
    "    # event == 0 (negative) の min と max を race_group ごとに計算\n",
    "    agg_neg = (\n",
    "        features_df.filter(pl.col(config.EVENT_COL) == 0)\n",
    "        .group_by(race_group)\n",
    "        .agg([pl.col(\"tmp_time\").min().alias(\"min_time_neg\"), pl.col(\"tmp_time\").max().alias(\"max_time_neg\")])\n",
    "    )\n",
    "\n",
    "    # event == 1 (positive) の min と max を race_group ごとに計算\n",
    "    agg_pos = (\n",
    "        features_df.filter(pl.col(config.EVENT_COL) == 1)\n",
    "        .group_by(race_group)\n",
    "        .agg([pl.col(\"tmp_time\").min().alias(\"min_time_pos\"), pl.col(\"tmp_time\").max().alias(\"max_time_pos\")])\n",
    "    )\n",
    "    features_df = features_df.join(agg_neg, on=race_group, how=\"left\").join(agg_pos, on=race_group, how=\"left\")\n",
    "    features_df = features_df.with_columns(\n",
    "        [\n",
    "            # event == 0 の場合: 1 - ((tmp_time - min_time_neg) / (max_time_neg - min_time_neg))\n",
    "            (\n",
    "                1 - ((pl.col(\"tmp_time\") - pl.col(\"min_time_neg\")) / (pl.col(\"max_time_neg\") - pl.col(\"min_time_neg\")))\n",
    "            ).alias(\"scaled_survival_time\"),\n",
    "            # event == 1 の場合: (tmp_time - min_time_pos) / (max_time_pos - min_time_pos)\n",
    "            ((pl.col(\"tmp_time\") - pl.col(\"min_time_pos\")) / (pl.col(\"max_time_pos\") - pl.col(\"min_time_pos\"))).alias(\n",
    "                \"scaled_survival_time_inv\"\n",
    "            ),\n",
    "        ]\n",
    "    ).with_columns(\n",
    "        # event に応じた weight の計算\n",
    "        pl.when(pl.col(config.EVENT_COL) == 0)\n",
    "        .then(pl.col(\"scaled_survival_time\") * (0.5 - 0.1) + 0.1)\n",
    "        .otherwise(pl.col(\"scaled_survival_time_inv\") * (1.5 - 1) + 1)\n",
    "        .alias(\"weight\")\n",
    "    )\n",
    "\n",
    "    return features_df\n",
    "\n",
    "\n",
    "features_df = add_weight_by_race_group(features_df, race_group=\"race_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_result_df, va_scores = pl.DataFrame(), {}\n",
    "for seed in config.SEEDS:\n",
    "    name = f\"cat_{seed}\"\n",
    "    _va_result_df, _va_scores, trained_models = single_train_fn(\n",
    "        model=CatBoostRegressorWrapper(\n",
    "            name=name,\n",
    "            model=CatBoostRegressor(\n",
    "                loss_function=\"Tweedie:variance_power=1.5\",\n",
    "                grow_policy=\"SymmetricTree\",\n",
    "                learning_rate=0.05,\n",
    "                n_estimators=100000,\n",
    "                early_stopping_rounds=3000,\n",
    "                eval_metric=CatBoostMetric(),\n",
    "                verbose=100,\n",
    "                random_state=seed,\n",
    "                colsample_bylevel=0.2,\n",
    "            ),\n",
    "            multi_output=False,\n",
    "            feature_names=feature_names,\n",
    "            cat_features=cat_features,\n",
    "        ),\n",
    "        features_df=add_kfold(\n",
    "            features_df,\n",
    "            n_splits=config.N_SPLITS,\n",
    "            random_state=seed,\n",
    "            fold_col=config.FOLD_COL,\n",
    "        ),\n",
    "        feature_cols=feature_names,\n",
    "        target_col=\"t_kmf_event_scaled2\",\n",
    "        fold_col=config.FOLD_COL,\n",
    "        meta_cols=config.META_COLS,\n",
    "        weight_col=\"weight\",\n",
    "        out_dir=config.OUTPUT_DIR,\n",
    "        train_folds=None,\n",
    "        eval_fn=Metric(),\n",
    "        overwrite=True,\n",
    "        use_eval_metric_extra_va_df=True,\n",
    "    )\n",
    "    va_result_df = pl.concat([va_result_df, _va_result_df], how=\"diagonal_relaxed\")\n",
    "    va_scores[name] = _va_scores\n",
    "\n",
    "# ------------------------------\n",
    "# final score\n",
    "# ------------------------------\n",
    "va_result_agg_df = (\n",
    "    va_result_df.group_by(config.ID_COL)\n",
    "    .agg(pl.col(\"pred\").mean())\n",
    "    .sort(\"ID\")\n",
    "    .join(train_test_df.select(config.META_COLS), on=config.ID_COL, how=\"left\")\n",
    ")\n",
    "final_score = Metric()(input_df=va_result_agg_df)\n",
    "logger.info(f\"✅ final score: {final_score}\")\n",
    "va_scores[\"final\"] = final_score\n",
    "\n",
    "# save\n",
    "va_result_agg_df.write_csv(f\"{config.OUTPUT_DIR}/va_result.csv\")\n",
    "with open(f\"{config.OUTPUT_DIR}/va_scores.json\", \"w\") as f:\n",
    "    json.dump(va_scores, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug test\n",
    "test_features_df = fe(config=config, train_test_df=train_test_df, output_dataset=\"TEST\")\n",
    "te_result_df = pl.DataFrame()\n",
    "for seed in config.SEEDS:\n",
    "    name = f\"cat_{seed}\"\n",
    "\n",
    "    _te_result_df = single_inference_fn(\n",
    "        model=CatBoostRegressorWrapper(name=name, feature_names=feature_names, cat_features=cat_features),\n",
    "        features_df=test_features_df,\n",
    "        feature_names=feature_names,\n",
    "        model_dir=config.ARTIFACT_EXP_DIR(),\n",
    "        inference_folds=list(range(config.N_SPLITS)),\n",
    "        out_dir=config.OUTPUT_DIR,\n",
    "    )\n",
    "    te_result_df = pl.concat([te_result_df, _te_result_df], how=\"diagonal_relaxed\")\n",
    "\n",
    "te_result_agg_df = (\n",
    "    te_result_df.group_by(config.ID_COL)\n",
    "    .agg(pl.col(\"pred\").mean())\n",
    "    .sort(\"ID\")\n",
    "    .join(train_test_df.select(config.META_COLS), on=config.ID_COL, how=\"left\")\n",
    ")\n",
    "\n",
    "\n",
    "print(te_result_agg_df[\"pred\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
