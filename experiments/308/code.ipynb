{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "import config\n",
    "import lightgbm as lgb\n",
    "import polars as pl\n",
    "from catboost import CatBoostRegressor\n",
    "from preprocess import fe, load_data\n",
    "\n",
    "from src.customs.fold import add_kfold\n",
    "from src.customs.metrics import CatBoostMetric, LGBMMetric, Metric\n",
    "from src.model.sklearn_like import (\n",
    "    CatBoostRegressorWrapper,\n",
    "    LightGBMWapper,\n",
    ")\n",
    "from src.trainer.tabular.simple import single_inference_fn, single_train_fn\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = load_data(config=config, valid_ratio=config.VALID_RATIO)\n",
    "target_df = pl.read_csv(\"./data/extr_output/101/1/101.csv\").with_columns(pl.col(\"t_event_pred\") * 2)\n",
    "target_cols = [x for x in target_df.columns if x.startswith(\"t_\")]\n",
    "train_test_df = train_test_df.join(\n",
    "    target_df.select(\n",
    "        [\n",
    "            config.ID_COL,\n",
    "            *target_cols,\n",
    "        ],\n",
    "    ),\n",
    "    on=config.ID_COL,\n",
    "    how=\"left\",\n",
    ")\n",
    "config.META_COLS = set(config.META_COLS) | set(target_cols)\n",
    "\n",
    "features_df = fe(config=config, train_test_df=train_test_df)\n",
    "feature_names = sorted([x for x in features_df.columns if x.startswith(config.FEATURE_PREFIX)])\n",
    "cat_features = [x for x in feature_names if x.startswith(f\"{config.FEATURE_PREFIX}c_\")]\n",
    "\n",
    "\n",
    "def make_new_targets(\n",
    "    df: pl.DataFrame,\n",
    "    base_target_names: tuple[str] = (\"t_kmf\", \"t_bfhf\"),\n",
    "    lower_bound_pos: float = 0.0,\n",
    "    lower_bound_neg: float = 0.0,\n",
    "    pred_col: str = \"t_event_pred\",\n",
    ") -> pl.DataFrame:\n",
    "    for base_target_name in base_target_names:\n",
    "        new_target_name = f\"{base_target_name}_event_scaled2\"\n",
    "\n",
    "        scaling_factor_pos = (\n",
    "            df.filter(pl.col(config.EVENT_COL) == 1)\n",
    "            .select(pl.col(pred_col).log().min() / (lower_bound_pos - pl.col(base_target_name).min()))[pred_col]\n",
    "            .to_numpy()[0]\n",
    "        )\n",
    "        scaling_factor_neg = (\n",
    "            df.filter(pl.col(config.EVENT_COL) == 0)\n",
    "            .select(pl.col(pred_col).log().min() / (lower_bound_neg - pl.col(base_target_name).min()))[pred_col]\n",
    "            .to_numpy()[0]\n",
    "        )\n",
    "\n",
    "        print(scaling_factor_pos, scaling_factor_neg)\n",
    "\n",
    "        new_df = df.select(\n",
    "            pl.col(config.ID_COL),\n",
    "            pl.when(pl.col(config.EVENT_COL) == 1)\n",
    "            .then(pl.col(pred_col).log() / scaling_factor_pos + pl.col(base_target_name))\n",
    "            .otherwise(pl.col(pred_col).log() / scaling_factor_neg + pl.col(base_target_name))\n",
    "            .alias(new_target_name),\n",
    "        )\n",
    "        df = df.join(new_df, on=config.ID_COL, how=\"left\")\n",
    "    return df\n",
    "\n",
    "\n",
    "features_df = features_df.join(\n",
    "    make_new_targets(\n",
    "        target_df,\n",
    "        lower_bound_neg=0.0,\n",
    "        lower_bound_pos=0.0,\n",
    "    ).select(pl.col(config.ID_COL), pl.col(\"t_kmf_event_scaled2\").exp()),\n",
    "    on=config.ID_COL,\n",
    "    how=\"left\",\n",
    ").with_columns((pl.col(\"t_kmf_event_scaled2\") / pl.col(\"t_kmf_event_scaled2\").max()).alias(\"t_kmf_event_scaled3\"))\n",
    "\n",
    "\n",
    "def add_weight(\n",
    "    features_df: pl.DataFrame,\n",
    "    survival_time_col: str,\n",
    "    event_col: str,\n",
    "    neg_min: float = 0.01,  # event == 0 の場合の下限\n",
    "    neg_max: float = 0.5,  # event == 0 の場合の上限\n",
    "    pos_min: float = 1.0,  # event == 1 の場合の下限\n",
    "    pos_max: float = 1.5,  # event == 1 の場合の上限\n",
    ") -> pl.DataFrame:\n",
    "    features_df = features_df.with_columns(pl.col(survival_time_col).alias(\"tmp_time\"))\n",
    "\n",
    "    # 各 event グループごとに tmp_time の最小値と最大値を計算\n",
    "    features_df = features_df.with_columns(\n",
    "        [\n",
    "            pl.col(\"tmp_time\").min().over(event_col).alias(\"group_min\"),\n",
    "            pl.col(\"tmp_time\").max().over(event_col).alias(\"group_max\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 各グループごとにスケーリングした値から weight を計算\n",
    "    features_df = features_df.with_columns(\n",
    "        pl.when(pl.col(event_col) == 0)\n",
    "        .then(\n",
    "            # event == 0 の場合は逆スケーリング: 1 - ((tmp_time - group_min) / (group_max - group_min))\n",
    "            (1 - ((pl.col(\"tmp_time\") - pl.col(\"group_min\")) / (pl.col(\"group_max\") - pl.col(\"group_min\"))))\n",
    "            * (neg_max - neg_min)\n",
    "            + neg_min\n",
    "        )\n",
    "        .otherwise(\n",
    "            # event == 1 の場合はそのままスケーリング: ((tmp_time - group_min) / (group_max - group_min))\n",
    "            ((pl.col(\"tmp_time\") - pl.col(\"group_min\")) / (pl.col(\"group_max\") - pl.col(\"group_min\")))\n",
    "            * (pos_max - pos_min)\n",
    "            + pos_min\n",
    "        )\n",
    "        .alias(\"weight\")\n",
    "    )\n",
    "\n",
    "    return features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_result_df, va_scores = pl.DataFrame(), {}\n",
    "for i, seed in enumerate(config.SEEDS):\n",
    "    name = f\"lgb_{seed}\"\n",
    "    _va_result_df, _va_scores, trained_models = single_train_fn(\n",
    "        model=LightGBMWapper(\n",
    "            name=name,\n",
    "            model=lgb.LGBMModel(\n",
    "                objective=\"cross_entropy\",\n",
    "                boosting=\"gbdt\",\n",
    "                n_estimators=100000,\n",
    "                learning_rate=0.01,\n",
    "                num_leaves=11 + (4 * i),\n",
    "                colsample_bytree=0.2,\n",
    "                subsample=0.9,\n",
    "                importance_type=\"gain\",\n",
    "                metric=\"None\",\n",
    "            ),\n",
    "            fit_params={\n",
    "                \"callbacks\": [\n",
    "                    lgb.early_stopping(3000, first_metric_only=True),\n",
    "                    lgb.log_evaluation(period=100),\n",
    "                ],\n",
    "                \"eval_metric\": LGBMMetric(),\n",
    "                \"categorical_feature\": cat_features,\n",
    "                \"feature_name\": feature_names,\n",
    "            },\n",
    "        ),\n",
    "        features_df=add_kfold(\n",
    "            add_weight(\n",
    "                features_df,\n",
    "                survival_time_col=config.SURVIVAL_TIME_COL,\n",
    "                event_col=config.EVENT_COL,\n",
    "                neg_min=0.5,\n",
    "                neg_max=0.5,\n",
    "                pos_min=1.0,\n",
    "                pos_max=1.0,\n",
    "            ),\n",
    "            n_splits=config.N_SPLITS,\n",
    "            random_state=seed,\n",
    "            fold_col=config.FOLD_COL,\n",
    "        ),\n",
    "        feature_cols=feature_names,\n",
    "        target_col=\"t_kmf_event_scaled3\",\n",
    "        fold_col=config.FOLD_COL,\n",
    "        meta_cols=config.META_COLS,\n",
    "        weight_col=\"weight\",\n",
    "        out_dir=config.OUTPUT_DIR,\n",
    "        train_folds=None,\n",
    "        eval_fn=Metric(),\n",
    "        overwrite=True,\n",
    "        use_eval_metric_extra_va_df=True,\n",
    "    )\n",
    "    va_result_df = pl.concat([va_result_df, _va_result_df], how=\"diagonal_relaxed\")\n",
    "    va_scores[name] = _va_scores\n",
    "\n",
    "# ------------------------------\n",
    "# final score\n",
    "# ------------------------------\n",
    "va_result_agg_df = (\n",
    "    va_result_df.group_by(config.ID_COL)\n",
    "    .agg(pl.col(\"pred\").mean())\n",
    "    .sort(\"ID\")\n",
    "    .join(train_test_df.select(config.META_COLS), on=config.ID_COL, how=\"left\")\n",
    ")\n",
    "final_score = Metric()(input_df=va_result_agg_df)\n",
    "logger.info(f\"✅ final score: {final_score}\")\n",
    "va_scores[\"final\"] = final_score\n",
    "\n",
    "# save\n",
    "va_result_agg_df.write_csv(f\"{config.OUTPUT_DIR}/va_result.csv\")\n",
    "with open(f\"{config.OUTPUT_DIR}/va_scores.json\", \"w\") as f:\n",
    "    json.dump(va_scores, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug test\n",
    "test_features_df = fe(config=config, train_test_df=train_test_df, output_dataset=\"TEST\")\n",
    "te_result_df = pl.DataFrame()\n",
    "for seed in config.SEEDS:\n",
    "    name = f\"lgb_{seed}\"\n",
    "\n",
    "    _te_result_df = single_inference_fn(\n",
    "        model=LightGBMWapper(name=name),\n",
    "        features_df=test_features_df,\n",
    "        feature_names=feature_names,\n",
    "        model_dir=config.ARTIFACT_EXP_DIR(),\n",
    "        inference_folds=list(range(config.N_SPLITS)),\n",
    "        out_dir=config.OUTPUT_DIR,\n",
    "    )\n",
    "    te_result_df = pl.concat([te_result_df, _te_result_df], how=\"diagonal_relaxed\")\n",
    "\n",
    "te_result_agg_df = (\n",
    "    te_result_df.group_by(config.ID_COL)\n",
    "    .agg(pl.col(\"pred\").mean())\n",
    "    .sort(\"ID\")\n",
    "    .join(train_test_df.select(config.META_COLS), on=config.ID_COL, how=\"left\")\n",
    ")\n",
    "\n",
    "\n",
    "print(te_result_agg_df[\"pred\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
